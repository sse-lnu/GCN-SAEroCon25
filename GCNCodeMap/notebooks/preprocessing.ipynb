{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e_0FgnzP7pCm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiCliEhZzrjc"
   },
   "source": [
    "## 1. Repositiories of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\JABEERAK\\GNN_mapGitHUb\\GCNCodeMap\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\JABEERAK\\GNN_mapGitHUb\\GCNCodeMap\\data\\raw')\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'jabref': r'jabref_labels.txt',\n",
    "            'sweetHome': r'sweethome3d_labels.txt',\n",
    "            'ant': r'ant_labels.txt',\n",
    "            'prom': r'prom_labels.txt',\n",
    "            'teammates': r'teammates_labels.txt',\n",
    "            'argouml': r'argouml_labels.txt',                   \n",
    "            'lucene': r'lucene_labels.txt',\n",
    "            'common': r'commons-imaging_labels.txt',        \n",
    "}\n",
    "\n",
    "roots = {\n",
    "    'jabref': 'net/sf/jabref/',\n",
    "    'sweetHome': 'com/eteks/sweethome3d/',\n",
    "    'ant': 'org/apache/tools/',\n",
    "    'prom': 'org/processmining/',\n",
    "    'teammates': 'teammates/',\n",
    "    'argouml': 'org/argouml/',\n",
    "    'lucene': 'org/apache/lucene/',\n",
    "    'common': 'org/apache/commons/imaging/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JABEERAK\\AppData\\Local\\Temp\\ipykernel_16448\\1124068398.py:145: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df.loc[df['Entity'].str.contains(file_pattern, regex=True, na=False), 'Module'] = module\n"
     ]
    }
   ],
   "source": [
    "def load_labels(labels_path):\n",
    "    \"\"\"Loads and parses the labels file into a structured dictionary.\"\"\"\n",
    "    with open(labels_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    lines = content.split('\\n')\n",
    "    data = {\n",
    "        'mapping': [],\n",
    "        'relations': [],\n",
    "        'roots': [],\n",
    "        'modules': []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            if line.strip().startswith('# root-packages'):\n",
    "                current_section = 'roots'\n",
    "            elif line.strip().startswith('# mapping'):\n",
    "                current_section = 'mapping'\n",
    "            elif line.strip().startswith('# relations'):\n",
    "                current_section = 'relations'\n",
    "            elif line.strip().startswith('# modules'):\n",
    "                current_section = 'modules'\n",
    "            continue\n",
    "\n",
    "        if current_section == 'mapping':\n",
    "            map_file = line.split()\n",
    "            if len(map_file) == 2:\n",
    "                data['mapping'].append({'Module': map_file[0], 'Entity': map_file[1]})\n",
    "        elif current_section == 'relations':\n",
    "            source_target = line.split()\n",
    "            if len(source_target) == 2:\n",
    "                data['relations'].append({'Source': source_target[0], 'Target': source_target[1]})\n",
    "        elif current_section == 'roots':\n",
    "            if '/' in line:\n",
    "                data['roots'].append(line.strip())\n",
    "        elif current_section == 'modules':\n",
    "            data['modules'].append(line.strip())\n",
    "\n",
    "    labels = pd.DataFrame(data['mapping'])\n",
    "    labels.Entity = labels.Entity.str.replace('..', '.')\n",
    "    labels.Entity = labels.Entity.str.replace('\\\\.', '/')\n",
    "    labels.Entity = labels.Entity.str.replace('*', '.*')\n",
    "    labels['Entity'] = labels['Entity'].str.replace(r\"\\(\\?:\\?!\", r\"(?!\", regex=True)\n",
    "\n",
    "    architecture = pd.DataFrame(data['relations'])\n",
    "\n",
    "    roots = data['roots']\n",
    "    if roots:\n",
    "        root = '|'.join([r.strip('/') for r in roots])\n",
    "        if '|' in root:\n",
    "            terms = root.split('|')\n",
    "            split_terms = [term.split('/') for term in terms]\n",
    "            common_term = set(split_terms[0]).intersection(*split_terms[1:])\n",
    "            if common_term:\n",
    "                root = common_term.pop()\n",
    "    else:\n",
    "        root = ''\n",
    "    return architecture, labels, root\n",
    "\n",
    "# Method to read JSON\n",
    "def read_json(file_path, encoding='utf-8'):\n",
    "    flattened_data_list = []\n",
    "    try:\n",
    "        with open(file_path, encoding=encoding) as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    flattened_data_list.append(pd.json_normalize(data))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding line: {line} -> {e}\")\n",
    "        flattened_data = pd.concat(flattened_data_list, ignore_index=True)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, encoding='latin-1') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    flattened_data_list.append(pd.json_normalize(data))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding line: {line} -> {e}\")\n",
    "        flattened_data = pd.concat(flattened_data_list, ignore_index=True)\n",
    "    return flattened_data\n",
    "\n",
    "# Method to clean the dataframe\n",
    "def cleaning(df, root):\n",
    "    df = df.copy()\n",
    "    df.rename(columns={'name': 'Entity'}, inplace=True)\n",
    "    df['Entity'] = df['Entity'].apply(lambda x: x.replace('.', '/'))\n",
    "    df = df[df['Entity'].str.contains(root)]\n",
    "    df['Entity'] = df['Entity'].apply(lambda x: x.split('$')[0])\n",
    "    df = df[~df['Entity'].str.contains('package-info')]\n",
    "    df['File'] = df['Entity'].apply(lambda x: x.split(root)[1])\n",
    "    df['File'] = df['File'].str.lstrip('/')\n",
    "    return df\n",
    "\n",
    "# Method to extract dependencies\n",
    "def extract_dependencies(df):\n",
    "    deps_list = []\n",
    "    entity_set = set(df['Entity'])\n",
    "    for deps in df['deps']:\n",
    "        if isinstance(deps, list):\n",
    "            deps_list.extend(deps)\n",
    "    \n",
    "    deps_df = pd.DataFrame(deps_list)\n",
    "    deps_df['source'] = deps_df['source'].apply(lambda x: x.replace('.', '/'))\n",
    "    deps_df['target'] = deps_df['target'].apply(lambda x: x.replace('.', '/'))\n",
    "    \n",
    "    deps_df = deps_df[deps_df['source'].isin(entity_set) & deps_df['target'].isin(entity_set)]\n",
    "    deps_df.drop_duplicates(inplace=True)\n",
    "    deps_df.rename(columns={'source': 'Source', 'target': 'Target', 'type': 'Dependency_Type', 'count': 'Dependency_Count'}, inplace=True)\n",
    "    \n",
    "    return deps_df\n",
    "\n",
    "# Method to clean and merge the entities\n",
    "def clean_and_merge_entities(df):\n",
    "    def clean_text_tokens(texts):\n",
    "        cleaned_texts = []\n",
    "        for token in texts:\n",
    "            if re.fullmatch(r'[\\n\\t]{1,}', token):\n",
    "                continue\n",
    "            if len(token) == 1 or token.isdigit() or not any(char.isalpha() for char in token):\n",
    "                continue\n",
    "            if token in ['<init>', '<clinit>', '<p>']:\n",
    "                continue\n",
    "            token = token.replace(':', '').replace(',', '').replace('$', '')\n",
    "            cleaned_texts.append(token)\n",
    "        return cleaned_texts\n",
    "    \n",
    "    df['texts'] = df['texts'].apply(lambda x: clean_text_tokens(x) if isinstance(x, list) else [])\n",
    "    merged_df = df.groupby('Entity', as_index=False).agg({\n",
    "        'texts': lambda x: list(set(sum(x, []))),\n",
    "        **{col: 'first' for col in df.columns if col not in ['Entity', 'texts']}\n",
    "    })\n",
    "    return merged_df\n",
    "\n",
    "# Method to get module from labels\n",
    "def get_module(df, labels):\n",
    "    df = df.copy()\n",
    "    df['Module'] = None\n",
    "    for _, row in labels.iterrows():\n",
    "        file_pattern = row['Entity']\n",
    "        module = row['Module']\n",
    "        df.loc[df['Entity'].str.contains(file_pattern, regex=True, na=False), 'Module'] = module\n",
    "    \n",
    "    dff = df.copy()\n",
    "    dff['File_ID'] = range(1, len(dff) + 1)\n",
    "    dff.rename(columns={'texts': 'Code'}, inplace=True)\n",
    "    dff = dff[~dff.Module.isna()]\n",
    "    file_id_map = dict(zip(dff['Entity'], dff['File_ID']))\n",
    "    dff = dff[['File_ID', 'File', 'Entity', 'Code', 'Module']]\n",
    "    \n",
    "    return dff, file_id_map\n",
    "\n",
    "# Method to get dependencies\n",
    "def get_dependencies(file_id_map, df, df_dep, architecture):\n",
    "    df_dep = df_dep.copy()\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_merged_source = pd.merge(df_dep, df[['Entity', 'Module']], left_on='Source', right_on='Entity', how='left')\n",
    "    df_merged_source = df_merged_source.rename(columns={'Module': 'Source_Module'}).drop(columns=['Entity'])\n",
    "    \n",
    "    df_merged_target = pd.merge(df_merged_source, df[['Entity', 'Module']], left_on='Target', right_on='Entity', how='left')\n",
    "    df_merged_target = df_merged_target.rename(columns={'Module': 'Target_Module'}).drop(columns=['Entity'])\n",
    "    \n",
    "    df_dep = df_merged_target.copy()\n",
    "    df_dep = df_dep[(~df_dep.Source_Module.isna()) & (~df_dep.Target_Module.isna())]\n",
    "    df_dep['Source_ID'] = df_dep['Source'].map(file_id_map)\n",
    "    df_dep['Target_ID'] = df_dep['Target'].map(file_id_map)\n",
    "    \n",
    "    df_dep = df_dep[['Source_ID', 'Source', 'Source_Module', 'Target_ID', 'Target', 'Target_Module', 'Dependency_Type', 'Dependency_Count']]\n",
    "    allowed_set = set(zip(architecture['Source'], architecture['Target']))\n",
    "    df_dep['Allowed'] = df_dep.apply(\n",
    "        lambda row: 1 if (row['Source_Module'], row['Target_Module']) in allowed_set or row['Source_Module'] == row['Target_Module']\n",
    "        else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    df_dep = df_dep[df_dep.Source != df_dep.Target]\n",
    "    df_dep.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df_dep\n",
    "def generate_Graph(df, dep):\n",
    "    modules = {file: df['Module'].iloc[i] for i, file in enumerate(df['File_ID'])}\n",
    "    nodes = {file: df['Entity'].iloc[i] for i, file in enumerate(df['File_ID'])}\n",
    "    G = nx.MultiDiGraph()\n",
    "    for file in nodes.keys():\n",
    "        G.add_node(file, code=nodes[file], label=modules[file])\n",
    "    for _, row in dep.iterrows():\n",
    "        if row['Source_ID'] in G.nodes and row['Target_ID'] in G.nodes:\n",
    "            G.add_edge(row['Source_ID'], row['Target_ID'], type=row['Dependency_Type'], weight=row['Dependency_Count'])\n",
    "            \n",
    "    df['Closeness_Centrality'] = df['File_ID'].map(nx.closeness_centrality(G))\n",
    "    return df\n",
    "\n",
    "architecture, labels, root = load_labels(labels_dict['teammates'])\n",
    "df = read_json('teammates.json')\n",
    "df = cleaning(df, root)\n",
    "df_dep = extract_dependencies(df)\n",
    "df = clean_and_merge_entities(df)\n",
    "df, file_id_map = get_module(df, labels)\n",
    "df_dep = get_dependencies(file_id_map, df, df_dep, architecture)\n",
    "df = generate_Graph(df, df_dep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_Module</th>\n",
       "      <th>Target_ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target_Module</th>\n",
       "      <th>Dependency_Type</th>\n",
       "      <th>Dependency_Count</th>\n",
       "      <th>Allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>teammates/ui/controller/InstructorCourseEditPa...</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>520</td>\n",
       "      <td>teammates/ui/controller/Action</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>Extends</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562</td>\n",
       "      <td>teammates/ui/controller/InstructorCourseEditPa...</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>520</td>\n",
       "      <td>teammates/ui/controller/Action</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>ConstructorCall</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562</td>\n",
       "      <td>teammates/ui/controller/InstructorCourseEditPa...</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>97</td>\n",
       "      <td>teammates/common/exception/EntityDoesNotExistE...</td>\n",
       "      <td>common.exception</td>\n",
       "      <td>Throws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562</td>\n",
       "      <td>teammates/ui/controller/InstructorCourseEditPa...</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>522</td>\n",
       "      <td>teammates/ui/controller/ActionResult</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>Returns</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>teammates/ui/controller/InstructorCourseEditPa...</td>\n",
       "      <td>ui.controller</td>\n",
       "      <td>112</td>\n",
       "      <td>teammates/common/util/Assumption</td>\n",
       "      <td>common.util</td>\n",
       "      <td>MethodCall</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11994</th>\n",
       "      <td>725</td>\n",
       "      <td>teammates/ui/template/FeedbackResponseCommentRow</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>65</td>\n",
       "      <td>teammates/common/datatransfer/attributes/Feedb...</td>\n",
       "      <td>common.dataTransfer</td>\n",
       "      <td>MethodCall</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>725</td>\n",
       "      <td>teammates/ui/template/FeedbackResponseCommentRow</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>65</td>\n",
       "      <td>teammates/common/datatransfer/attributes/Feedb...</td>\n",
       "      <td>common.dataTransfer</td>\n",
       "      <td>FieldUse</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>725</td>\n",
       "      <td>teammates/ui/template/FeedbackResponseCommentRow</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>137</td>\n",
       "      <td>teammates/common/util/TimeHelper</td>\n",
       "      <td>common.util</td>\n",
       "      <td>MethodCall</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>725</td>\n",
       "      <td>teammates/ui/template/FeedbackResponseCommentRow</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>38</td>\n",
       "      <td>teammates/common/datatransfer/FeedbackParticip...</td>\n",
       "      <td>common.dataTransfer</td>\n",
       "      <td>Argument</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>725</td>\n",
       "      <td>teammates/ui/template/FeedbackResponseCommentRow</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>38</td>\n",
       "      <td>teammates/common/datatransfer/FeedbackParticip...</td>\n",
       "      <td>common.dataTransfer</td>\n",
       "      <td>FieldUse</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11785 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source_ID                                             Source  \\\n",
       "0            562  teammates/ui/controller/InstructorCourseEditPa...   \n",
       "1            562  teammates/ui/controller/InstructorCourseEditPa...   \n",
       "2            562  teammates/ui/controller/InstructorCourseEditPa...   \n",
       "3            562  teammates/ui/controller/InstructorCourseEditPa...   \n",
       "4            562  teammates/ui/controller/InstructorCourseEditPa...   \n",
       "...          ...                                                ...   \n",
       "11994        725   teammates/ui/template/FeedbackResponseCommentRow   \n",
       "11995        725   teammates/ui/template/FeedbackResponseCommentRow   \n",
       "11996        725   teammates/ui/template/FeedbackResponseCommentRow   \n",
       "11997        725   teammates/ui/template/FeedbackResponseCommentRow   \n",
       "11999        725   teammates/ui/template/FeedbackResponseCommentRow   \n",
       "\n",
       "       Source_Module  Target_ID  \\\n",
       "0      ui.controller        520   \n",
       "1      ui.controller        520   \n",
       "2      ui.controller         97   \n",
       "3      ui.controller        522   \n",
       "4      ui.controller        112   \n",
       "...              ...        ...   \n",
       "11994        ui.view         65   \n",
       "11995        ui.view         65   \n",
       "11996        ui.view        137   \n",
       "11997        ui.view         38   \n",
       "11999        ui.view         38   \n",
       "\n",
       "                                                  Target        Target_Module  \\\n",
       "0                         teammates/ui/controller/Action        ui.controller   \n",
       "1                         teammates/ui/controller/Action        ui.controller   \n",
       "2      teammates/common/exception/EntityDoesNotExistE...     common.exception   \n",
       "3                   teammates/ui/controller/ActionResult        ui.controller   \n",
       "4                       teammates/common/util/Assumption          common.util   \n",
       "...                                                  ...                  ...   \n",
       "11994  teammates/common/datatransfer/attributes/Feedb...  common.dataTransfer   \n",
       "11995  teammates/common/datatransfer/attributes/Feedb...  common.dataTransfer   \n",
       "11996                   teammates/common/util/TimeHelper          common.util   \n",
       "11997  teammates/common/datatransfer/FeedbackParticip...  common.dataTransfer   \n",
       "11999  teammates/common/datatransfer/FeedbackParticip...  common.dataTransfer   \n",
       "\n",
       "       Dependency_Type  Dependency_Count  Allowed  \n",
       "0              Extends                 1        1  \n",
       "1      ConstructorCall                 1        1  \n",
       "2               Throws                 1        1  \n",
       "3              Returns                 1        1  \n",
       "4           MethodCall                 1        1  \n",
       "...                ...               ...      ...  \n",
       "11994       MethodCall                 1        1  \n",
       "11995         FieldUse                11        1  \n",
       "11996       MethodCall                 2        1  \n",
       "11997         Argument                 6        1  \n",
       "11999         FieldUse                17        1  \n",
       "\n",
       "[11785 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_ID</th>\n",
       "      <th>File</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Module</th>\n",
       "      <th>Closeness_Centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>client/remoteapi/RemoteApiClient</td>\n",
       "      <td>teammates/client/remoteapi/RemoteApiClient</td>\n",
       "      <td>[--- Remote operation completed ---, installer...</td>\n",
       "      <td>client.remoteAPI</td>\n",
       "      <td>0.020566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>client/scripts/AdminEmailListGenerator</td>\n",
       "      <td>teammates/client/scripts/AdminEmailListGenerator</td>\n",
       "      <td>[studentCreatedDateRangeStart, Date format err...</td>\n",
       "      <td>client.scripts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>client/scripts/DataBundleRegenerator</td>\n",
       "      <td>teammates/client/scripts/DataBundleRegenerator</td>\n",
       "      <td>[regenerateDataBundleJson, questionMap, regene...</td>\n",
       "      <td>client.scripts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>client/scripts/DataGenerator</td>\n",
       "      <td>teammates/client/scripts/DataGenerator</td>\n",
       "      <td>[numOfStudent, \"\"email\"\", \"instructors\"{\\n, St...</td>\n",
       "      <td>client.scripts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>client/scripts/DataMigrationForFeedbackRespons...</td>\n",
       "      <td>teammates/client/scripts/DataMigrationForFeedb...</td>\n",
       "      <td>[document, comments analyzed., comment, allCom...</td>\n",
       "      <td>client.scripts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>775</td>\n",
       "      <td>ui/template/StudentListStudentData</td>\n",
       "      <td>teammates/ui/template/StudentListStudentData</td>\n",
       "      <td>[courseIdForJs, googleId, courseid, getStudent...</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>776</td>\n",
       "      <td>ui/template/StudentListTeamData</td>\n",
       "      <td>teammates/ui/template/StudentListTeamData</td>\n",
       "      <td>[getStudents, googleId, team, students, sessio...</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>0.006610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>777</td>\n",
       "      <td>ui/template/StudentProfile</td>\n",
       "      <td>teammates/ui/template/StudentProfile</td>\n",
       "      <td>[pictureUrl, nationality, moreInfo, getEmail, ...</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>0.007490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>778</td>\n",
       "      <td>ui/template/StudentProfileEditBox</td>\n",
       "      <td>teammates/ui/template/StudentProfileEditBox</td>\n",
       "      <td>[getEmail, googleId, nationalitySelectField, g...</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>779</td>\n",
       "      <td>ui/template/StudentProfileUploadPhotoModal</td>\n",
       "      <td>teammates/ui/template/StudentProfileUploadPhot...</td>\n",
       "      <td>[pictureUrl, getGoogleId, getPictureKey, googl...</td>\n",
       "      <td>ui.view</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>779 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_ID                                               File  \\\n",
       "0          1                   client/remoteapi/RemoteApiClient   \n",
       "1          2             client/scripts/AdminEmailListGenerator   \n",
       "2          3               client/scripts/DataBundleRegenerator   \n",
       "3          4                       client/scripts/DataGenerator   \n",
       "4          5  client/scripts/DataMigrationForFeedbackRespons...   \n",
       "..       ...                                                ...   \n",
       "774      775                 ui/template/StudentListStudentData   \n",
       "775      776                    ui/template/StudentListTeamData   \n",
       "776      777                         ui/template/StudentProfile   \n",
       "777      778                  ui/template/StudentProfileEditBox   \n",
       "778      779         ui/template/StudentProfileUploadPhotoModal   \n",
       "\n",
       "                                                Entity  \\\n",
       "0           teammates/client/remoteapi/RemoteApiClient   \n",
       "1     teammates/client/scripts/AdminEmailListGenerator   \n",
       "2       teammates/client/scripts/DataBundleRegenerator   \n",
       "3               teammates/client/scripts/DataGenerator   \n",
       "4    teammates/client/scripts/DataMigrationForFeedb...   \n",
       "..                                                 ...   \n",
       "774       teammates/ui/template/StudentListStudentData   \n",
       "775          teammates/ui/template/StudentListTeamData   \n",
       "776               teammates/ui/template/StudentProfile   \n",
       "777        teammates/ui/template/StudentProfileEditBox   \n",
       "778  teammates/ui/template/StudentProfileUploadPhot...   \n",
       "\n",
       "                                                  Code            Module  \\\n",
       "0    [--- Remote operation completed ---, installer...  client.remoteAPI   \n",
       "1    [studentCreatedDateRangeStart, Date format err...    client.scripts   \n",
       "2    [regenerateDataBundleJson, questionMap, regene...    client.scripts   \n",
       "3    [numOfStudent, \"\"email\"\", \"instructors\"{\\n, St...    client.scripts   \n",
       "4    [document, comments analyzed., comment, allCom...    client.scripts   \n",
       "..                                                 ...               ...   \n",
       "774  [courseIdForJs, googleId, courseid, getStudent...           ui.view   \n",
       "775  [getStudents, googleId, team, students, sessio...           ui.view   \n",
       "776  [pictureUrl, nationality, moreInfo, getEmail, ...           ui.view   \n",
       "777  [getEmail, googleId, nationalitySelectField, g...           ui.view   \n",
       "778  [pictureUrl, getGoogleId, getPictureKey, googl...           ui.view   \n",
       "\n",
       "     Closeness_Centrality  \n",
       "0                0.020566  \n",
       "1                0.000000  \n",
       "2                0.000000  \n",
       "3                0.000000  \n",
       "4                0.000000  \n",
       "..                    ...  \n",
       "774              0.005431  \n",
       "775              0.006610  \n",
       "776              0.007490  \n",
       "777              0.002938  \n",
       "778              0.002938  \n",
       "\n",
       "[779 rows x 6 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --labels LABELS --json JSON --name NAME\n",
      "ipykernel_launcher.py: error: the following arguments are required: --labels, --json, --name\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JABEERAK\\.conda\\envs\\torchDL\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "def load_labels(labels_path):\n",
    "    \"\"\"Loads and parses the labels file into a structured dictionary.\"\"\"\n",
    "    with open(labels_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    lines = content.split('\\n')\n",
    "    data = {\n",
    "        'mapping': [],\n",
    "        'relations': [],\n",
    "        'roots': [],\n",
    "        'modules': []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            if line.strip().startswith('# root-packages'):\n",
    "                current_section = 'roots'\n",
    "            elif line.strip().startswith('# mapping'):\n",
    "                current_section = 'mapping'\n",
    "            elif line.strip().startswith('# relations'):\n",
    "                current_section = 'relations'\n",
    "            elif line.strip().startswith('# modules'):\n",
    "                current_section = 'modules'\n",
    "            continue\n",
    "\n",
    "        if current_section == 'mapping':\n",
    "            map_file = line.split()\n",
    "            if len(map_file) == 2:\n",
    "                data['mapping'].append({'Module': map_file[0], 'Entity': map_file[1]})\n",
    "        elif current_section == 'relations':\n",
    "            source_target = line.split()\n",
    "            if len(source_target) == 2:\n",
    "                data['relations'].append({'Source': source_target[0], 'Target': source_target[1]})\n",
    "        elif current_section == 'roots':\n",
    "            if '/' in line:\n",
    "                data['roots'].append(line.strip())\n",
    "        elif current_section == 'modules':\n",
    "            data['modules'].append(line.strip())\n",
    "\n",
    "    labels = pd.DataFrame(data['mapping'])\n",
    "    labels.Entity = labels.Entity.str.replace('..', '.')\n",
    "    labels.Entity = labels.Entity.str.replace('\\\\.', '/')\n",
    "    labels.Entity = labels.Entity.str.replace('*', '.*')\n",
    "    labels['Entity'] = labels['Entity'].str.replace(r\"\\(\\?:\\?!\", r\"(?!\", regex=True)\n",
    "\n",
    "    architecture = pd.DataFrame(data['relations'])\n",
    "\n",
    "    roots = data['roots']\n",
    "    if roots:\n",
    "        root = '|'.join([r.strip('/') for r in roots])\n",
    "        if '|' in root:\n",
    "            terms = root.split('|')\n",
    "            split_terms = [term.split('/') for term in terms]\n",
    "            common_term = set(split_terms[0]).intersection(*split_terms[1:])\n",
    "            if common_term:\n",
    "                root = common_term.pop()\n",
    "    else:\n",
    "        root = ''\n",
    "    return architecture, labels, root\n",
    "\n",
    "def read_json(file_path, encoding='utf-8'):\n",
    "    flattened_data_list = []\n",
    "    try:\n",
    "        with open(file_path, encoding=encoding) as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    flattened_data_list.append(pd.json_normalize(data))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding line: {line} -> {e}\")\n",
    "        flattened_data = pd.concat(flattened_data_list, ignore_index=True)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, encoding='latin-1') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    flattened_data_list.append(pd.json_normalize(data))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding line: {line} -> {e}\")\n",
    "        flattened_data = pd.concat(flattened_data_list, ignore_index=True)\n",
    "    return flattened_data\n",
    "\n",
    "# Method to clean the dataframe\n",
    "def cleaning(df, root):\n",
    "    df = df.copy()\n",
    "    df.rename(columns={'name': 'Entity'}, inplace=True)\n",
    "    df['Entity'] = df['Entity'].apply(lambda x: x.replace('.', '/'))\n",
    "    df = df[df['Entity'].str.contains(root)]\n",
    "    df['Entity'] = df['Entity'].apply(lambda x: x.split('$')[0])\n",
    "    df = df[~df['Entity'].str.contains('package-info')]\n",
    "    df['File'] = df['Entity'].apply(lambda x: x.split(root)[1])\n",
    "    df['File'] = df['File'].str.lstrip('/')\n",
    "    return df\n",
    "\n",
    "# Method to extract dependencies\n",
    "def extract_dependencies(df):\n",
    "    deps_list = []\n",
    "    entity_set = set(df['Entity'])\n",
    "    for deps in df['deps']:\n",
    "        if isinstance(deps, list):\n",
    "            deps_list.extend(deps)\n",
    "    \n",
    "    deps_df = pd.DataFrame(deps_list)\n",
    "    deps_df['source'] = deps_df['source'].apply(lambda x: x.replace('.', '/'))\n",
    "    deps_df['target'] = deps_df['target'].apply(lambda x: x.replace('.', '/'))\n",
    "    \n",
    "    deps_df = deps_df[deps_df['source'].isin(entity_set) & deps_df['target'].isin(entity_set)]\n",
    "    deps_df.drop_duplicates(inplace=True)\n",
    "    deps_df.rename(columns={'source': 'Source', 'target': 'Target', 'type': 'Dependency_Type', 'count': 'Dependency_Count'}, inplace=True)\n",
    "    \n",
    "    return deps_df\n",
    "\n",
    "# Method to clean and merge the entities\n",
    "def clean_and_merge_entities(df):\n",
    "    def clean_text_tokens(texts):\n",
    "        cleaned_texts = []\n",
    "        for token in texts:\n",
    "            if re.fullmatch(r'[\\n\\t]{1,}', token):\n",
    "                continue\n",
    "            if len(token) == 1 or token.isdigit() or not any(char.isalpha() for char in token):\n",
    "                continue\n",
    "            if token in ['<init>', '<clinit>', '<p>']:\n",
    "                continue\n",
    "            token = token.replace(':', '').replace(',', '').replace('$', '')\n",
    "            cleaned_texts.append(token)\n",
    "        return cleaned_texts\n",
    "    \n",
    "    df['texts'] = df['texts'].apply(lambda x: clean_text_tokens(x) if isinstance(x, list) else [])\n",
    "    merged_df = df.groupby('Entity', as_index=False).agg({\n",
    "        'texts': lambda x: list(set(sum(x, []))),\n",
    "        **{col: 'first' for col in df.columns if col not in ['Entity', 'texts']}\n",
    "    })\n",
    "    return merged_df\n",
    "\n",
    "# Method to get module from labels\n",
    "def get_module(df, labels):\n",
    "    df = df.copy()\n",
    "    df['Module'] = None\n",
    "    for _, row in labels.iterrows():\n",
    "        file_pattern = row['Entity']\n",
    "        module = row['Module']\n",
    "        df.loc[df['Entity'].str.contains(file_pattern, regex=True, na=False), 'Module'] = module\n",
    "    \n",
    "    dff = df.copy()\n",
    "    dff['File_ID'] = range(1, len(dff) + 1)\n",
    "    dff.rename(columns={'texts': 'Code'}, inplace=True)\n",
    "    dff = dff[~dff.Module.isna()]\n",
    "    file_id_map = dict(zip(dff['Entity'], dff['File_ID']))\n",
    "    dff = dff[['File_ID', 'File', 'Entity', 'Code', 'Module']]\n",
    "    \n",
    "    return dff, file_id_map\n",
    "\n",
    "# Method to get dependencies\n",
    "def get_dependencies(file_id_map, df, df_dep, architecture):\n",
    "    df_dep = df_dep.copy()\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_merged_source = pd.merge(df_dep, df[['Entity', 'Module']], left_on='Source', right_on='Entity', how='left')\n",
    "    df_merged_source = df_merged_source.rename(columns={'Module': 'Source_Module'}).drop(columns=['Entity'])\n",
    "    \n",
    "    df_merged_target = pd.merge(df_merged_source, df[['Entity', 'Module']], left_on='Target', right_on='Entity', how='left')\n",
    "    df_merged_target = df_merged_target.rename(columns={'Module': 'Target_Module'}).drop(columns=['Entity'])\n",
    "    \n",
    "    df_dep = df_merged_target.copy()\n",
    "    df_dep = df_dep[(~df_dep.Source_Module.isna()) & (~df_dep.Target_Module.isna())]\n",
    "    df_dep['Source_ID'] = df_dep['Source'].map(file_id_map)\n",
    "    df_dep['Target_ID'] = df_dep['Target'].map(file_id_map)\n",
    "    \n",
    "    df_dep = df_dep[['Source_ID', 'Source', 'Source_Module', 'Target_ID', 'Target', 'Target_Module', 'Dependency_Type', 'Dependency_Count']]\n",
    "    allowed_set = set(zip(architecture['Source'], architecture['Target']))\n",
    "    df_dep['Allowed'] = df_dep.apply(\n",
    "        lambda row: 1 if (row['Source_Module'], row['Target_Module']) in allowed_set or row['Source_Module'] == row['Target_Module']\n",
    "        else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    df_dep = df_dep[df_dep.Source != df_dep.Target]\n",
    "    df_dep.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df_dep\n",
    "def generate_Graph(df, dep):\n",
    "    modules = {file: df['Module'].iloc[i] for i, file in enumerate(df['File_ID'])}\n",
    "    nodes = {file: df['Entity'].iloc[i] for i, file in enumerate(df['File_ID'])}\n",
    "    G = nx.MultiDiGraph()\n",
    "    for file in nodes.keys():\n",
    "        G.add_node(file, code=nodes[file], label=modules[file])\n",
    "    for _, row in dep.iterrows():\n",
    "        if row['Source_ID'] in G.nodes and row['Target_ID'] in G.nodes:\n",
    "            G.add_edge(row['Source_ID'], row['Target_ID'], type=row['Dependency_Type'], weight=row['Dependency_Count'])\n",
    "            \n",
    "    df['Closeness_Centrality'] = df['File_ID'].map(nx.closeness_centrality(G))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def main(labels_path, json_path, dataset_name):\n",
    "\n",
    "    architecture, labels, root = load_labels(labels_path)\n",
    "    df = read_json(json_path)\n",
    "    df = cleaning(df, root)\n",
    "    df_dep = extract_dependencies(df)\n",
    "    df = clean_and_merge_entities(df)\n",
    "    df, file_id_map = get_module(df, labels)\n",
    "    df_dep = get_dependencies(file_id_map, df, df_dep, architecture)\n",
    "    df = generate_Graph(df, df_dep)\n",
    "    processed_dir = os.path.join(\"data\", \"processed\")\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "    # Save processed data in the processed directory\n",
    "    df.to_csv(os.path.join(processed_dir, f'df_{dataset_name}.csv'), index=False)\n",
    "    df_dep.to_csv(os.path.join(processed_dir, f'dep_{dataset_name}.csv'), index=False)\n",
    "    print(f\"Processing complete. Results saved in '{processed_dir}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Process JSON and labels files.\")\n",
    "    parser.add_argument('--labels', required=True, help=\"Path to the labels file\")\n",
    "    parser.add_argument('--json', required=True, help=\"Path to the JSON file\")\n",
    "    parser.add_argument('--name', required=True, help=\"Name of the dataset (used for output files)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args.labels, args.json, args.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
